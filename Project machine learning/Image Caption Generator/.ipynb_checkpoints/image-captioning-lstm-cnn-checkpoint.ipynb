{
 "cells": [
  {
   "attachments": {
    "4effd468-0bec-44be-bfe2-1de91c81fb90.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": false
   },
   "source": [
    "# **Objective**\n",
    "#### **This notebook** is dedicated to exploring the application of **Long Short-Term Memory (LSTM)** models for **image captioning** on a small dataset. **Image captioning** is a fascinating task that **combines computer vision** and **natural language processing** to **generate** meaningful **textual descriptions based on visual content**. The primary aim is to provide a **detailed guide** for individuals interested in **constructing and comprehending LSTM models**. This step-by-step tutorial **elucidates** the process of **building** a model **based on LSTM** for image captioning tasks.\n",
    "\n",
    "### What is an **LSTM**?\n",
    "> ##### **Long Short-Term Memory (LSTM)** is a **type of recurrent neural network (RNN)** architecture designed to **handle sequential data**. LSTMs are particularly adept at capturing **long-range dependencies** and are widely utilized in various tasks, including (NLP) and other sequence-to-sequence tasks. **Unlike traditional RNNs**, LSTMs **are equipped** with memory cells and gating mechanisms, allowing them to **effectively address the vanishing gradient** problem and capture temporal dependencies.\n",
    "\n",
    "> ![lstm-architecture-768x532.PNG](attachment:4effd468-0bec-44be-bfe2-1de91c81fb90.PNG)\n",
    "\n",
    "> ##### **Input Gate:** The input gate **controls** how much of the **new information** should be added **to the cell state**.\n",
    "> ##### **Forget Gate:** The forget gate decides **what information from the previous cell** state should be **discarded**.\n",
    "> ##### **Update of Cell State:** The cell state is updated **based on the input gate, forget gate,** and a new **candidate** cell state\n",
    "> ##### **Output Gate:** The output gate **determines** the **next hidden state** based on the updated cell state.\n",
    "> ##### **Final Hidden State:** The final hidden state is **determined** by the **output gate** and the **updated cell state**\n",
    "\n",
    "## **Methodology:**\n",
    "> #### 1. **Data and Pre-processing:**\n",
    "> ##### The **Flickr8k** dataset is utilized, and pre-processing involves **caption normalization**, and dataset splitting. Image processing includes conversion to arrays, and **feature extraction** using a pre-trained **Inception v3** model are applied. The dataset is prepared using **generators** for **optimized memory usage** during training.\n",
    "\n",
    "> #### 2. **Model Architecture:**\n",
    "> ##### **The encoder** employs normalization and **dense layers** to **align dimensions** with the decoder. **The decoder** incorporates **an embedding layer**, and **an LSTM layer**. **Ultimately** an Add layer and **two Dense layers** serve as the **output layers**.\n",
    "\n",
    "> #### 3. **Training:**\n",
    "> ##### **The training** process involves utilizing **image features** as inputs **for the encoder** and their corresponding five **captions** as inputs for **the decoder**. At each time step, the **image features** (x_image) **are combined with partial captions** (x_captions) **up to the current time step**, while **the target captions** (y_target) **represent the next word** in the sequence. The primary objective during training is to iteratively **update the model's weights**, **minimizing the loss** and enhancing its ability to generate accurate and coherent captions.\n",
    "\n",
    "> #### 4. **Inference:**\n",
    "> ##### **Greedy algorithm** and **Beam Search** combined with **BLEU score evaluation** are employed for generating captions on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 23:35:07.440868: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-04 23:35:07.440900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-04 23:35:07.441829: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, add\n",
    "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images\n",
    "images_directory = '/kaggle/input/flickr8k/Images/'\n",
    "# Path to the captions\n",
    "captions_path = '/kaggle/input/flickr8k/captions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/flickr8k/captions.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Loading the captions from the dataset\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m captions \u001b[38;5;241m=\u001b[39m load_captions(captions_path)\n\u001b[1;32m     15\u001b[0m captions[:\u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload_captions\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_captions\u001b[39m(file_path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         captions \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# Lowercasing  the captions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/flickr8k/captions.txt'"
     ]
    }
   ],
   "source": [
    "def load_captions(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        captions = f.readlines()\n",
    "        # Lowercasing  the captions\n",
    "        captions = [caption.lower() for caption in captions[1:]]\n",
    "    return captions\n",
    "\n",
    "def tokenize_captions(captions):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(captions)\n",
    "    return tokenizer\n",
    "\n",
    "# Loading the captions from the dataset\n",
    "captions = load_captions(captions_path)\n",
    "captions[:15:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Removing punctuation marks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Removing numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Removing extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Cleaning the captions\n",
    "cleaned_captions = [clean_text(caption.split(',')[1]) for caption in captions]\n",
    "cleaned_captions[:15:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image ID + \\t + Caption\n",
    "captions_IDs = []\n",
    "for i in range(len(cleaned_captions)):\n",
    "    #  Adding 'start' word and 'end' word to the captions\n",
    "    item = captions[i].split(',')[0]+'\\t'+'start '+cleaned_captions[i]+' end\\n'\n",
    "    captions_IDs.append(item)\n",
    "    \n",
    "captions_IDs[:20:3], len(captions_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some of the images along with their corresponding captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def visualaization(data, num_of_images):\n",
    "    # We use dictionaries to access captions of each image by its ID\n",
    "    captions_dictionary = {}\n",
    "    for item in data[100:100+(num_of_images)*5]:\n",
    "        image_id, caption = item.split('\\t')\n",
    "        if image_id not in captions_dictionary:\n",
    "            captions_dictionary[image_id] = []\n",
    "        captions_dictionary[image_id].append(caption)\n",
    "    else:\n",
    "        list_captions = [x for x in captions_dictionary.items()]\n",
    "    \n",
    "    count = 1\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "    for filename in list(captions_dictionary.keys()):\n",
    "        captions = captions_dictionary[filename]\n",
    "        image_load = load_img(images_directory+filename, target_size=(199,199,3))\n",
    "\n",
    "        ax = fig.add_subplot(num_of_images,2,count,xticks=[],yticks=[])\n",
    "        ax.imshow(image_load)\n",
    "        count += 1\n",
    "\n",
    "        ax = fig.add_subplot(num_of_images,2,count)\n",
    "        plt.axis('off')\n",
    "        ax.plot()\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.set_ylim(0,len(captions))\n",
    "        for i, caption in enumerate(captions):\n",
    "            ax.text(0,i,caption,fontsize=20)\n",
    "        count += 1\n",
    "    plt.show()\n",
    "    \n",
    "visualaization(captions_IDs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def captions_length(data):\n",
    "    plt.figure(figsize=(15, 7), dpi=300)\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.histplot(x=[len(x.split(' ')) for x in data], kde=True, binwidth=1) \n",
    "    plt.title('Captions length histogram', fontsize=15, fontweight='bold')\n",
    "    plt.xticks(fontweight='bold')\n",
    "    plt.yticks(fontweight='bold')\n",
    "    plt.xlabel('Length', fontweight='bold')\n",
    "    plt.ylabel('Freaquency', fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "captions_length(cleaned_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def word_occurrences(data):\n",
    "    # Combining all sentences into a single string\n",
    "    all_text = ' '.join(data)\n",
    "    # Splitting the text into words and count occurrences\n",
    "    word_counts = Counter(all_text.split())\n",
    "\n",
    "    words = list(word_counts.keys())[1:30]\n",
    "    values = list(word_counts.values())[1:30]\n",
    "\n",
    "    # Normalize values to be between 0 and 1\n",
    "    normalized_values = np.array(values) / np.max(values)\n",
    "    colors = np.array(['rgba(30, 58, 138, {})'.format(0.4 + 0.5 * (value)) for value in normalized_values])\n",
    "\n",
    "    fig = go.Figure(data=[go.Pie(labels=words, values=values, hole=.6, marker=dict(colors=colors), textinfo='label')])\n",
    "\n",
    "    fig.update_layout(title_text='Word occurrences in captions (except for letter \\'a\\')', title_font=dict(size=23, family='Balto'))\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "word_occurrences(cleaned_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizing** captions and setting **vocab size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the captions and creating word-to-index mapping\n",
    "tokenizer = tokenize_captions(cleaned_captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into tain, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Storing all image IDs\n",
    "all_image_ids = os.listdir(images_directory)\n",
    "\n",
    "# Splitting image IDs\n",
    "train_image_ids, val_image_ids = train_test_split(all_image_ids, test_size=0.15, random_state=42)\n",
    "val_image_ids, test_image_ids = train_test_split(val_image_ids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_captions, val_captions, test_captions = [], [], []\n",
    "for caption in captions_IDs:\n",
    "    image_id, _ = caption.split('\\t')\n",
    "    \n",
    "    if image_id in train_image_ids:\n",
    "        train_captions.append(caption)\n",
    "        \n",
    "    elif image_id in val_image_ids:\n",
    "        val_captions.append(caption)        \n",
    "\n",
    "    elif image_id in test_image_ids:\n",
    "        test_captions.append(caption)\n",
    "        \n",
    "    else:\n",
    "        print('Unknown image ID !')\n",
    "\n",
    "train_captions[0], val_captions[0], test_captions[0], len(train_captions)/5, len(val_captions)/5, len(test_captions)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracting Image features** using **The InceptionV3** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(299, 299))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def extract_image_features(model, image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    features = model.predict(img, verbose=0)\n",
    "    return features\n",
    "\n",
    "# Loading the pre-trained InceptionV3 model\n",
    "inception_v3_model = InceptionV3(weights = 'imagenet', input_shape=(299, 299, 3))\n",
    "inception_v3_model.layers.pop()\n",
    "inception_v3_model = Model(inputs=inception_v3_model.inputs, outputs=inception_v3_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_features, val_image_features, test_image_features = {}, {}, {}  # A Dictionary to store image features with their corresponding IDs       \n",
    "\n",
    "pbar = tqdm_notebook(total=len(all_image_ids), position=0, leave=True, colour='green') \n",
    "\n",
    "for caption in all_image_ids:\n",
    "    image_id = caption.split('\\t')[0]\n",
    "    image_path = os.path.join(images_directory, image_id)\n",
    "    image_features = extract_image_features(inception_v3_model, image_path) # Extracting features\n",
    "    \n",
    "    if image_id in train_image_ids:\n",
    "        train_image_features[image_id] = image_features.flatten()  # Flattening the features\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elif image_id in val_image_ids:\n",
    "        val_image_features[image_id] = image_features.flatten()  # Flattening the features\n",
    "        pbar.update(1)\n",
    "    \n",
    "    elif image_id in test_image_ids:\n",
    "        test_image_features[image_id] = image_features.flatten()  # Flattening the features\n",
    "        pbar.update(1)\n",
    "    \n",
    "    else:\n",
    "        print('Unknown image ID !')\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Setup for Model Input**\n",
    "> #### To **optimize** memory usage, it's suggested to use **generators** to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_generator(captions, image_features, tokenizer, max_caption_length, batch_size):\n",
    "    num_samples = len(captions)\n",
    "    image_ids = list(image_features.keys())\n",
    "    while True:\n",
    "        np.random.shuffle(image_ids)  # Shuffle image_ids for each epoch\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            X_images, X_captions, y = [], [], []\n",
    "            for caption in captions[start_idx:end_idx]:\n",
    "                image_id, caption_text = caption.split('\\t')\n",
    "                caption_text = caption_text.rstrip('\\n')\n",
    "                seq = tokenizer.texts_to_sequences([caption_text])[0] # Tokenizing the caption\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i] # X_caption, Y\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_caption_length)[0]\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    X_images.append(image_features[image_id])\n",
    "                    X_captions.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            \n",
    "            yield [np.array(X_images), np.array(X_captions)], np.array(y)\n",
    "         \n",
    "        \n",
    "# Defining the maximum length of captions\n",
    "max_caption_length = max(len(caption.split()) for caption in cleaned_captions) + 1\n",
    "\n",
    "# Defining the CNN output dimension (size of feature vector from InceptionV3)\n",
    "cnn_output_dim = inception_v3_model.output_shape[1] # 2048\n",
    "\n",
    "# Defining batch size\n",
    "batch_size_train = 270\n",
    "batch_size_val = 150\n",
    "\n",
    "# Creating data generators for training and validation\n",
    "train_data_generator = data_generator(train_captions, train_image_features, tokenizer, max_caption_length, batch_size_train)\n",
    "val_data_generator = data_generator(val_captions, val_image_features, tokenizer, max_caption_length, batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shapes\n",
    "sample_batch = next(train_data_generator)\n",
    "print(\"Training sample batch shapes:\")\n",
    "print(\"X_images:\", sample_batch[0][0].shape)\n",
    "print(\"X_captions:\", sample_batch[0][1].shape)\n",
    "print(\"y:\", sample_batch[1].shape)\n",
    "print('=========================')\n",
    "sample_batch = next(val_data_generator)\n",
    "print(\"Validation sample batch shapes:\")\n",
    "print(\"X_images:\", sample_batch[0][0].shape)\n",
    "print(\"X_captions:\", sample_batch[0][1].shape)\n",
    "print(\"y:\", sample_batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Defining** the **Image Captioning** Model\n",
    "\n",
    "> ### **Encoder** (image features)\n",
    "> * Input Layer\n",
    "> * Batch Normalization Layer\n",
    "> * Dense Layer\n",
    "> * Batch Normalization Layer\n",
    "\n",
    "> ### **Decoder** (captions)\n",
    "> * Input Layer\n",
    "> * Embedding Layer\n",
    "> * **LSTM** Layer\n",
    "\n",
    "> ### **Output**\n",
    "> * Add Layer (Encoder output + Decoder output)\n",
    "> * Dense Layer + ReLU activation function\n",
    "> * Dense Layer + Softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, max_caption_length, cnn_output_dim):\n",
    "    # Encoder Model\n",
    "    input_image = Input(shape=(cnn_output_dim,), name='Features_Input')\n",
    "    fe1 = BatchNormalization()(input_image)\n",
    "    fe2 = Dense(256, activation='relu')(fe1) # Adding a Dense layer to the CNN output to match the decoder output size\n",
    "    fe3 = BatchNormalization()(fe2)\n",
    "    \n",
    "    # Decoder Model\n",
    "    input_caption = Input(shape=(max_caption_length,), name='Sequence_Input')\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(input_caption)\n",
    "    se2 = LSTM(256)(se1)\n",
    "    \n",
    "    # Output\n",
    "    decoder1 = add([fe3, se2])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax', name='Output_Layer')(decoder2)\n",
    "\n",
    "    # Returning The Model\n",
    "    model = Model(inputs=[input_image, input_caption], outputs=outputs, name='Image_Captioning')\n",
    "    return model\n",
    "    \n",
    "# Building the model\n",
    "caption_model = build_model(vocab_size, max_caption_length, cnn_output_dim)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01, clipnorm=1.0)\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "caption_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(caption_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "##### **Training** will **stop** if there is **no improvement** in the **validation loss** for **3 consecutive epochs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * tf.math.exp(-0.6)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "history = caption_model.fit(train_data_generator, steps_per_epoch=len(train_captions) // batch_size_train,\n",
    "                        validation_data=val_data_generator, validation_steps=len(val_captions) // batch_size_val,\n",
    "                        epochs=15, callbacks=[early_stopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7), dpi=200)\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot([x+1 for x in range(len(history.history['loss']))], history.history['loss'], color='#E74C3C', marker='o')\n",
    "plt.plot([x+1 for x in range(len(history.history['loss']))], history.history['val_loss'], color='#641E16', marker='h')\n",
    "plt.title('Train VS Validation', fontsize=15, fontweight='bold')\n",
    "plt.xticks(fontweight='bold')\n",
    "plt.yticks(fontweight='bold')\n",
    "plt.xlabel('Epoch', fontweight='bold')\n",
    "plt.ylabel('Loss', fontweight='bold')\n",
    "plt.legend(['Train Loss', 'Validation Loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "> ##### **Caption Generation:** At **each time step**, **the model takes** as input **the image features** along with **the generated words** (starting with start at the first time step), **predicting the probabilities** of **the next word**.\n",
    "> ##### **Greedy algorithm:** To select  **the best caption**, **the greedy algorithm** is employed. This method, chooses **the most probable word** at each time step and **appends it** to the generated captions **until** the selected word is the **end** token, **or the length** of the decoded captions exceeds  **the maximum sequence length**.\n",
    "> ##### **Beam Search:** Beam Search is an **alternative** to the greedy algorithm for **selecting captions**. It **maintains** a beam of **multiple hypotheses** (candidate captions) at each time step. At each step, **the model predicts** the next word for **each hypothesis**. **The top-k candidates** (based on probabilities) **are retained** in the beam. The process **continues until** the **end token** is generated **or the maximum sequence length** is reached.\n",
    "> ##### **Evaluation** is performed using the **BLEU score**\n",
    "> ##### **Visualization:** The function visualization() plots the **images along with their corresponding predicted captions, accompanied by 2 BLEU scores**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_generator(image_features): # A function to generate captions\n",
    "    # Each caption is started with the word 'start'\n",
    "    in_text = 'start '\n",
    "    for _ in range(max_caption_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_caption_length).reshape((1,max_caption_length))\n",
    "        prediction = caption_model.predict([image_features.reshape(1,cnn_output_dim), sequence], verbose=0)\n",
    "        idx = np.argmax(prediction)\n",
    "        word = tokenizer.index_word[idx]\n",
    "        # Adding the predicted word to the sequence\n",
    "        in_text += ' ' + word\n",
    "        # When the model returns the word 'end' (which is the end word), the generating loop must be stopped \n",
    "        if word == 'end':\n",
    "            break\n",
    "            \n",
    "    in_text = in_text.replace('start ', '')\n",
    "    in_text = in_text.replace(' end', '')\n",
    "    \n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_generator(image_features, K_beams = 3, log = False):\n",
    "    start = [tokenizer.word_index['start']]\n",
    "    \n",
    "    start_word = [[start, 0.0]]\n",
    "    \n",
    "    for _ in range(max_caption_length):\n",
    "        temp = []\n",
    "        for s in start_word:\n",
    "            # Sequence of most probable words based on the previous steps\n",
    "            sequence  = pad_sequences([s[0]], maxlen=max_caption_length).reshape((1,max_caption_length))\n",
    "            \n",
    "            preds = caption_model.predict([image_features.reshape(1,cnn_output_dim), sequence], verbose=0)\n",
    "            \n",
    "            # Sorting predictions by the probability and taking the last K_beams items.\n",
    "            word_preds = np.argsort(preds[0])[-K_beams:]\n",
    "            \n",
    "            # Getting the top <K_beams>(n) predictions and creating a \n",
    "            #                              new list so as to put them via the model again.\n",
    "            for w in word_preds:\n",
    "                \n",
    "                next_cap, prob = s[0][:], s[1]\n",
    "                next_cap.append(w)\n",
    "                if log:\n",
    "                    prob += np.log(preds[0][w]) # assign a probability to each K words\n",
    "                else:\n",
    "                    prob += preds[0][w]\n",
    "                temp.append([next_cap, prob])\n",
    "                \n",
    "        start_word = temp\n",
    "        # Sorting according to the probabilities\n",
    "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
    "\n",
    "        # Getting the top words\n",
    "        start_word = start_word[-K_beams:]\n",
    "    \n",
    "    start_word = start_word[-1][0]\n",
    "    captions_ = [tokenizer.index_word[i] for i in start_word]\n",
    "\n",
    "    final_caption = []\n",
    "    \n",
    "    for i in captions_:\n",
    "        if i != 'end':\n",
    "            final_caption.append(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_caption = ' '.join(final_caption[1:])\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates BLEU score of predictions\n",
    "def BLEU_score(actual, greedy, beam_search):\n",
    "    # Calculating the BLEU score by comparing the predicted caption with five actual captions.\n",
    "    score_greedy_1 = corpus_bleu(actual, greedy, weights=(0.3, 0.3, 0.3, 0))\n",
    "    score_greedy_2 = corpus_bleu(actual, greedy, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    score_BS_1 = corpus_bleu(actual, beam_search, weights=(0.3, 0.3, 0.3, 0))\n",
    "    score_BS_2 = corpus_bleu(actual, beam_search, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    \n",
    "    return [\n",
    "        (f'BLEU-2 Greedy: {round(score_BS_2, 5)}'),\n",
    "        (f'BLEU-1 Greedy: {round(score_BS_1, 5)}'),\n",
    "        (f'Greedy: {greedy[0]}'),\n",
    "        (f'BLEU-2 Beam Search: {round(score_greedy_2, 5)}'),\n",
    "        (f'BLEU-1 Beam Search: {round(score_greedy_1, 5)}'),\n",
    "        (f'Beam Search:  {beam_search[0]}')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to access actual captions of each image by its ID\n",
    "test_actual_captions = {}\n",
    "for item in test_captions:\n",
    "    image_id, caption = item.split('\\t')\n",
    "    if image_id not in test_actual_captions:\n",
    "        test_actual_captions[image_id] = []\n",
    "    test_actual_captions[image_id].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating captions\n",
    "generated_captions = {}\n",
    "\n",
    "pbar = tqdm_notebook(total=len(test_image_features), position=0, leave=True, colour='green')\n",
    "for image_id in test_image_features:\n",
    "    cap = greedy_generator(test_image_features[image_id])\n",
    "    generated_captions[image_id] = cap\n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some of the **test images** along with their corresponding **generated captions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def visualization(data, greedy_caps, beamS_generator, evaluator, num_of_images):\n",
    "    keys = list(data.keys()) # List of all test images\n",
    "    images = [np.random.choice(keys) for i in range(num_of_images)] # Randomly selected images\n",
    "    \n",
    "    count = 1\n",
    "    fig = plt.figure(figsize=(6,20))    \n",
    "    for filename in images:\n",
    "        actual_cap = data[filename]\n",
    "        actual_cap = [x.replace(\"start \", \"\") for x in actual_cap] # Removing the start token\n",
    "        actual_cap = [x.replace(\" end\", \"\") for x in actual_cap] # Removing the end token\n",
    "        \n",
    "        # Generating captions\n",
    "        greedy_cap = greedy_caps[filename]\n",
    "        beamS_cap = beamS_generator(test_image_features[filename])\n",
    "        \n",
    "        # Getting the bleu score\n",
    "        caps_with_score = evaluator(actual_cap, [greedy_cap]*(len(actual_cap)), [beamS_cap]*(len(actual_cap)))\n",
    "    \n",
    "        image_load = load_img(images_directory+filename, target_size=(199,199,3))\n",
    "        ax = fig.add_subplot(num_of_images,2,count,xticks=[],yticks=[])\n",
    "        ax.imshow(image_load)\n",
    "        count += 1\n",
    "\n",
    "        ax = fig.add_subplot(num_of_images,2,count)\n",
    "        plt.axis('off')\n",
    "        ax.plot()\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.set_ylim(0,len(caps_with_score))\n",
    "        for i, text in enumerate(caps_with_score):\n",
    "            ax.text(0,i,text,fontsize=10)\n",
    "        count += 1\n",
    "    plt.show()\n",
    "\n",
    "visualization(test_actual_captions, generated_captions, beam_search_generator, BLEU_score, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "captions_length(list(generated_captions.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "word_occurrences(list(generated_captions.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better results achieved by utilizing  transformers on both the Flickr8k and Flickr30k datasets.\n",
    "> #### For those interested in exploring this further, here are the relevant resources:\n",
    "> #### Transformers for Flickr8k: https://www.kaggle.com/code/saeedghamshadzai/image-captioning-transformers-flickr8k\n",
    "> #### Transformers for Flickr30k: https://www.kaggle.com/code/saeedghamshadzai/image-captioning-transformers-flickr30k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Thank you** for taking the time to explore this notebook. I hope you found it both **enjoyable** and **informative**. **Please consider upvoting, sharing**, and **trying out** the concepts presented. **Feel free to share your thoughts, questions, or suggestions** in the **comment section** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Happy coding!**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
